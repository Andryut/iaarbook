Summary:Libro online de la comunidad de Inteligencia Artificial Argentina IAAR - Glosario de principales términos utilizados en Inteligencia artificial, ciencia de datos, deep learning y machine learning.

# Glosario de Inteligencia Artificial, Machine Learning y Ciencia de Datos

En esta sección van a poder encontrar las definiciones de los términos más utilizados en el mundo de la [Inteligencia Artificial](https://iaarbook.github.io/inteligencia-artificial/) y la [Ciencia de Datos](https://iaarbook.github.io/datascience/).

[A](#A) - [B](#B) - [C](#C) - [D](#D) - [E](#E) - [F](#F) - [G](#G) - [H](#H) - [I](#I) - [J](#J) - [K](#K) - [L](#L) - [M](#M) - [N](#N) - [O](#O) - [P](#P) - [Q](#Q) - [R](#R) - [S](#S) - [T](#T) - [U](#U) - [V](#V) - [W](#W) - [X](#X) - [Y](#Y) - [Z](#Z)


<a name="A"></a>
### Algoritmo <a name="Algoritmo"></a>
Una serie de pasos repetibles para llevar a cabo cierto tipo de tarea con datos. Al estudiar [Ciencia de Datos](https://iaarbook.github.io/datascience/) debemos conocer los diferentes algoritmos y sus respectivas ventajas y desventajas.

### Aprendizaje supervisado <a name="AprendSupervisado"></a>
En [Machine Learning](https://iaarbook.github.io/machine-learning/) el [aprendizaje supervisado](https://es.wikipedia.org/wiki/Aprendizaje_supervisado) es una técnica para deducir una función a partir de datos de entrenamiento. Los datos de entrenamiento consisten de pares de objetos (normalmente [vectores](#Vector)): un componente del par son los datos de entrada y el otro, los resultados deseados, es decir, los resultados a los que debe arribar el [modelo](#Modelo).

### Aprendizaje no supervisado <a name="AprendNoSupervisado"></a>
El [aprendizaje no supervisado](https://es.wikipedia.org/wiki/Aprendizaje_no_supervisado) es un método de [Machine Learning](https://iaarbook.github.io/machine-learning/) en donde el [modelo](#Modelo) es ajustado a las observaciones. En este caso el [algoritmo](#Algoritmo) es entrenado usando un [conjuntos de datos](#ConjDatos) que no tiene ninguna etiqueta; nunca se le dice lo que representan los datos. La idea es que el [algoritmo](#Algoritmo) pueda encontrar por si solo patrones que ayuden a entender los datos.

### Aprendizaje por refuerzo <a name="AprendRefuerzo"></a>
En los problemas de [aprendizaje por refuerzo](https://es.wikipedia.org/wiki/Aprendizaje_por_refuerzo), el [algoritmo](#Algoritmo) aprende observando el mundo que le rodea. Su información de entrada es el feedback o retroalimentación que obtiene del mundo exterior como respuesta a sus acciones. Por lo tanto, el sistema aprende en base a prueba-error.

### Arboles de Decisión <a name="DecTree"></a>
Los [Arboles de Decision](https://es.wikipedia.org/wiki/%C3%81rbol_de_decisi%C3%B3n) son un [algoritmo](#Algoritmo) de [Machine Learning](https://iaarbook.github.io/machine-learning/) que consisten en diagramas con construcciones lógicas, muy similares a los sistemas de predicción basados en reglas, que sirven para representar y categorizar una serie de condiciones que ocurren de forma sucesiva, para la resolución de un problema.

### Atributos <a name="Atributos"></a>
Los <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">Atributos</a> son las propiedades individuales que se pueden medir de un fenómeno que se observa. La elección de atributos informativos, discriminatorios e independientes es un paso crucial para la eficacia de los algoritmos de [Machine Learning](https://iaarbook.github.io/machine-learning/).

<a name="B"></a>
### Backpropagation <a name="Backprop"></a>
La [propagación hacia atrás](https://es.wikipedia.org/wiki/Propagaci%C3%B3n_hacia_atr%C3%A1s) o backpropagation es un  [algoritmo](#Algoritmo) para el ajuste iterativo de los pesos utilizados por las [redes neuronales](#RedNeuronal).

### BCI <a name="BCI"></a>
[BCI](https://es.wikipedia.org/wiki/Interfaz_cerebro-computadora) o *Brain Computer interfaces* constituyen una tecnología que se basa en la adquisición de [ondas cerebrales](https://es.wikipedia.org/wiki/Ondas_cerebrales) para luego ser procesadas e interpretadas por una máquina u ordenador. Establecen el camino para interactuar con el exterior mediante nuestro pensamiento.

### Big Data <a name="BigData"></a>
La [Big Data](https://iaarbook.github.io/bigdata/) es la rama de las [Teconlogías de la información](http://es.wikipedia.org/wiki/Tecnolog%C3%ADas_de_la_informaci%C3%B3n_y_la_comunicaci%C3%B3n) que estudia las dificultades inherentes a la manipulación de grandes [conjuntos de datos](#ConjDatos).

<a name="C"></a>
### Ciencia de datos <a name="CienciaDatos"></a>
La [Ciencia de Datos](https://iaarbook.github.io/datascience/) es un campo interdisciplinario que involucra métodos científicos, procesos y sistemas para extraer conocimiento o un mejor entendimiento de datos en sus diferentes formas, ya sea estructurados o no estructurados. 

### Clasificación <a name="Clasificacion"></a>
En [Machine Learning](https://iaarbook.github.io/machine-learning/) los problemas de **Clasificación** son aquellos en dónde el [algoritmo](#Algoritmo) de aprendizaje debe *clasificar* una serie de [vectores](#Vector) en base a información de ejemplos previamente etiquetados. Es una caso típico del [Aprendizaje supervisado](#AprendSupervisado)

### Clustering <a name="Clustering"></a>
El [Clustering](https://es.wikipedia.org/wiki/An%C3%A1lisis_de_grupos) o agrupamiento consiste en agrupar un un conjunto de objetos de tal manera que los miembros del mismo grupo (llamado *clúster*) sean más similares, en algún sentido u otro. Es el caso típico del [Aprendizaje no supervisado](#AprendNoSupervisado).

### Computación en la nube <a name="CloudComp"></a>
La [computación en la nube](https://es.wikipedia.org/wiki/Computaci%C3%B3n_en_la_nube) es un paradigma que permite ofrecer servicios de computación a través de una red, que usualmente es la [internet](https://es.wikipedia.org/wiki/Internet). Los servicios que generalmente se ofrecen, se dividen en tres grandes categorías: [Infraestructura como servicio (IaaS)](https://es.wikipedia.org/wiki/Computaci%C3%B3n_en_la_nube#Infraestructura_como_servicio), [plataforma como servicio (PaaS)](https://es.wikipedia.org/wiki/Computaci%C3%B3n_en_la_nube#Plataforma_como_servicio) y [software como servicio (SaaS)](https://es.wikipedia.org/wiki/Computaci%C3%B3n_en_la_nube#Software_como_servicio).

### Conjunto de datos <a name="ConjDatos"></a>
Un [Conjunto de datos](https://es.wikipedia.org/wiki/Conjunto_de_datos) o dataset es una colección de [Datos](#Datos) que habitualmente están estructurados en forma tabular.

<a name="D"></a>
### Datos <a name="Datos"></a>
Un [dato](https://es.wikipedia.org/wiki/Dato) es una representación simbólica (numérica, alfabética, algorítmica, espacial, etc.) de un atributo o variable cuantitativa o cualitativa. Los datos describen hechos empíricos, sucesos y entidades. Es el elemento fundamental con el que trabaja la [Ciencia de Datos](https://iaarbook.github.io/datascience/).

### Deep Learning <a name="DeepLearning"></a>
El [Deep Learning](https://iaarbook.github.io/deeplearning/) o aprendizaje profundo es un subcampo dentro del [Machine Learning](https://iaarbook.github.io/machine-learning/), el cuál utiliza distintas estructuras de [redes neuronales](#RedNeuronal) para lograr el aprendizaje de sucesivas capas de representaciones cada vez más significativas de los datos. Actualmente es el campo con más popularidad dentro de la [Inteligencia Artificial](https://iaarbook.github.io/inteligencia-artificial/).

<a name="E"></a>
### Estadística <a name="Estadistica"></a>
La [Estadística](http://relopezbriega.github.io/category/pobabilidad-y-estadistica.html) suele ser definida como la ciencia de aprender de los datos o como la ciencia de obtener conclusiones en la presencia de incertidumbre. Se divide en dos grandes ramas: [Estadística descriptiva](#EstDescrip) y [Estadística inferencial](#EstInf)

### Estadística Descriptiva <a name="EstDescrip"></a>
La [estadística descriptiva](https://es.wikipedia.org/wiki/Estad%C3%ADstica_descriptiva) se dedica a recolectar, ordenar, analizar y representar a un [conjunto de datos](#ConjDatos), con el fin de *describir* apropiadamente las características de este. Calcula los parámetros estadísticos que describen el conjunto estudiado. Algunas de las herramientas que utiliza son gráficos, medidas de frecuencias, medidas de centralización, medidas de posición, medidas de dispersión, entre otras.

### Estadística Inferencial <a name="EstInf"></a>
La [estadistica inferencial](https://es.wikipedia.org/wiki/Estad%C3%ADstica_inferencial) estudia cómo sacar conclusiones generales para toda la población a partir del estudio de una [muestra](#Muestra), y el grado de fiabilidad o significación de los resultados obtenidos. Sus principales herramientas son el muestreo, la estimación de parámetros y el contraste de [hipótesis](#Hipotesis).

<a name="F"></a>
### Función de activación <a name="FuncActiv"></a>
En [redes neuronales](#RedNeuronal) la [Función de activación](https://es.wikipedia.org/wiki/Funci%C3%B3n_de_activaci%C3%B3n) es la que define la forma en que una [neurona](#Neurona) se activa de acuerdo a una entrada o conjunto de entradas. 

### Función de pérdida <a name="FuncPerd"></a>
En [Machine Learning](https://iaarbook.github.io/machine-learning/) y [Optimización](#Optimizacion), la [Función de pérdida](https://en.wikipedia.org/wiki/Loss_functions_for_classification) es aquella que representa la *pérdida* de información o el precio pagado por la inexactitud en las predicciones. 

<a name="G"></a>
### Gradiente <a name="Gradiente"></a>
El concepto de [Gradiente](https://es.wikipedia.org/wiki/Gradiente) es la generalización de derivada a funciones de más de una variable o [vectores](#Vector). Un método de [Optimización](#Optimizacion) muy utilizado en [Deep Learning](https://iaarbook.github.io/deeplearning/) es el de [gradientes descendientes](https://en.wikipedia.org/wiki/Gradient_descent). 

<a name="H"></a>
### Hadoop <a name="Hadoop"></a>
[Hadoop](http://hadoop.apache.org/) es un [framework de software](http://es.wikipedia.org/wiki/Framework), desarrollado en el lenguaje de programación [Java](#Java), que permite el procesamiento distribuido de grandes [conjuntos de datos](#ConjDatos) a través de [clusters](http://es.wikipedia.org/wiki/Cluster_%28inform%C3%A1tica%29) de computadoras utilizando simples modelos de programación.

### Hipótesis <a name="Hipotesis"></a>
En [Estadística](http://relopezbriega.github.io/category/pobabilidad-y-estadistica.html), una [Hipótesis](https://es.wikipedia.org/wiki/Hip%C3%B3tesis) es una suposición de algo posible o imposible para sacar de ello una o más conclusiones. Su valor reside en la capacidad para establecer más relaciones entre los hechos y explicar por qué se producen. La misma debe ser contrastada contra los [datos](#Datos) que la soporten. 

<a name="I"></a>
### [IAAR](http://iaar.site/) <a name="IAAR"></a>
[IAAR](http://iaar.site/) es la comunidad argentina de [Inteligencia Artificial](https://iaarbook.github.io/inteligencia-artificial/). 

### Inteligencia Artificial <a name="IA"></a>
La [Inteligencia Artificial](https://iaarbook.github.io/inteligencia-artificial/) es el estudio de la inforseramática centrándose en el desarrollo de software o **máquinas que exhiben una inteligencia humana**.

### Interfaz cerebro computadora <a name="InterfazCerebroComp"></a>
La [interfaz cerebro computadora](https://iaarbook.github.io/interfaz-cerebro-computadora-BCI/) o BCI es un campo multidisciplinario que utiliza los nuevos avances en [neurociencia](https://es.wikipedia.org/wiki/Neurociencia), [procesamiento de señales](https://es.wikipedia.org/wiki/Procesamiento_digital_de_se%C3%B1ales), [machine learning](#ML) y las [tecnologías de la información](https://es.wikipedia.org/wiki/Tecnolog%C3%ADas_de_la_informaci%C3%B3n_y_la_comunicaci%C3%B3n) para explorar la forma de comunicar nuestro cerebro en forma directa con las máquinas, de la misma forma en que lo hacemos con nuestro cuerpo. 

### Internet de las cosas <a name="IoT"></a>
La [Internet de las cosas](https://iaarbook.github.io/internet-de-las-cosas/) o IoT es un concepto que se refiere a la interconexión digital de objetos cotidianos con internet, permitiendo la creación de un sin fin de sistemas inteligentes que aprovechan los beneficios de la [Big Data](https://iaarbook.github.io/bigdata/).

<a name="J"></a>
### Java <a name="Java"></a>
<a href="http://es.wikipedia.org/wiki/Java_(lenguaje_de_programaci%C3%B3n)">Java</a> es un lenguaje de programación [orientado a objetos](https://es.wikipedia.org/wiki/Programaci%C3%B3n_orientada_a_objetos) diseñado para ser multiplataforma y poder ser empleado el mismo programa en diversos sistemas operativos. Es uno de los lenguajes más utilizados en el mundo empresarial por su alto rendimiento. 

### Javascript <a name="Javascript"></a>
[Javascript](https://es.wikipedia.org/wiki/JavaScript) es el lenguaje de programación de la [Web](https://es.wikipedia.org/wiki/World_Wide_Web). Se caracteriza por ser fácil de aprender, [orientado a objetos](https://es.wikipedia.org/wiki/Programaci%C3%B3n_orientada_a_objetos), interpretado y basado en prototipos. Es ideal para generar contenido dinámico en [internet](https://es.wikipedia.org/wiki/Internet).

<a name="K"></a>
### Keras <a name="Keras"></a>
[Keras](https://keras.io/) es una librería de alto nivel para [Deep Learning](https://iaarbook.github.io/deeplearning/), muy fácil de utilizar. Está escrita y mantenida por Francis Chollet, miembro del equipo de Google Brain. Permite a los usuarios elegir si los modelos que se construyen serán ejecutados en el grafo simbólico de [Theano](http://deeplearning.net/software/theano/), [TensorFlow](https://www.tensorflow.org/) o [CNTK](https://www.microsoft.com/en-us/research/product/cognitive-toolkit/).

### K-Means <a name="K-Means"></a>
[K-means](https://es.wikipedia.org/wiki/K-means) es un [algoritmo](#Algoritmo) de [Machine Learning](https://iaarbook.github.io/machine-learning/) [no supervisado](#AprendNoSupervisado) muy popular para problemas de *Agrupamiento*; funciona reduciendo al mínimo la suma de las distancias cuadradas desde la media dentro de un agrupamiento. Para hacer esto establece primero un número previamente especificado de conglomerados, $K$, y luego va asignando cada observación a la agrupación más cercana de acuerdo a su media.

### KNN <a name="KNN"></a>
[KNN](https://es.wikipedia.org/wiki/K-vecinos_m%C3%A1s_cercanos) o K vecinos más cercanos es un [algoritmo](#Algoritmo) de [Machine Learning](https://iaarbook.github.io/machine-learning/) que consiste en realizar predicciones sobre una *clase* en base a la *clase* a la que pertenecen los puntos vecinos más cercanos al que intentamos predecir.

<a name="M"></a>
### Machine Learning <a name="ML"></a>
El [Machine Learning](https://iaarbook.github.io/machine-learning/) o aprendizaje automático es el diseño y estudio de las herramientas informáticas que **utilizan la experiencia pasada para tomar decisiones futuras**; es el estudio de programas que pueden aprender de los datos. El objetivo fundamental del [Machine Learning](https://iaarbook.github.io/machine-learning/) es ***generalizar, o inducir una regla desconocida a partir de ejemplos donde esa regla es aplicada***. 

### Matrices <a name="Matriz"></a>
Una <a href="http://es.wikipedia.org/wiki/Matriz_(matem%C3%A1ticas)">matriz</a> es un arreglo bidimensional de números (llamados entradas de la matriz) ordenados en filas (o renglones) y columnas, donde una fila es cada una de las líneas horizontales de la matriz y una columna es cada una de las líneas verticales. En una matriz cada elemento puede ser identificado utilizando dos índices, uno para la fila y otro para la columna en que se encuentra.

### Modelo <a name="Modelo"></a>
En [Machine Learning](https://iaarbook.github.io/machine-learning/), un *modelo* es el objeto que va a representar la salida del [algoritmo](#Algoritmo) de aprendizaje. El *modelo* es lo que utilizamos para realizar las predicciones. 

### Muestra <a name="Muestra"></a>
En [Estadística](http://relopezbriega.github.io/category/pobabilidad-y-estadistica.html) un [muestra](https://es.wikipedia.org/wiki/Muestra_estad%C3%ADstica) es un subconjunto de casos o individuos de una población. Debemos tratar que la misma sea lo más representativa posible.

<a name="N"></a>
### Neurona <a name="Neurona"></a>
Una **Neurona** en una [red neuronal artificial](#RedNeuronal) es una aproximación matemática de una [neurona biológica](https://es.wikipedia.org/wiki/Neurona). Requiere un [vector](#Vector) de entradas, realiza una transformación en los datos y genera un único valor de salida. Puede ser pensado como un filtro.

<a name="O"></a>
### Open Source <a name="OpenSource"></a>
[Open Source](http://es.wikipedia.org/wiki/C%C3%B3digo_abierto) es un modelo de desarrollo de software que se caracteriza por promover el rápido desarrollo e implementación de mejoras y corrección de errores en una solución de software. Su principal característica es que el código fuente es distribuido junto con la solución de software; por lo que cualquiera puede acceder a ver como esta construido el software y proponer mejoras  o modificarlo a su gusto. Se basa en el principio fundamental de que la información debe circular libremente, sin restricciones.

### Optimización <a name="Optimizacion"></a>
La [Optimización](http://relopezbriega.github.io/blog/2017/01/18/problemas-de-optimizacion-con-python/) consiste en la selección del mejor elemento (con respecto a algún criterio) de un conjunto de elementos disponibles. En el caso más simple, un *problema de optimización* consiste en *maximizar* o *minimizar* una función real eligiendo sistemáticamente valores de entrada (tomados de un conjunto permitido) y computando el valor de la función.

<a name="P"></a>
### Probabilidad <a name="Probabilidad"></a>
La [Probabilidad](http://relopezbriega.github.io/category/pobabilidad-y-estadistica.html) es la rama de las matemáticas que se ocupa de los fenómenos aleatorios y de la incertidumbre. Existen muchos eventos que no se pueden predecir con certeza; ya que su observación repetida bajo un mismo conjunto específico de condiciones puede arrojar resultados distintos, mostrando un comportamiento errático e impredecible. En estas situaciones, la [Probabilidad](http://relopezbriega.github.io/category/pobabilidad-y-estadistica.html) proporciona los métodos para cuantificar las posibilidades asociadas con los diversos resultados. 

### Procesamiento del lenguaje natural <a name="NLP"></a>
El [Procesamiento del lenguaje natural](https://iaarbook.github.io/NLP/) es una disciplina interdisciplinaria cuya idea central es la de darle a las máquinas la capacidad de leer y comprender los idiomas que hablamos los humanos. La investigación del [Procesamiento del lenguaje natural](https://iaarbook.github.io/NLP/) tiene como objetivo responder a la pregunta de cómo las personas son capaces de comprender el significado de una oración oral / escrita y cómo las personas entienden lo que sucedió, cuándo y dónde sucedió; y las diferencias entre una suposición, una creencia o un hecho.

### Python <a name="Python"></a>
[Python](https://iaarbook.github.io/python/) es actualmente uno de los lenguajes más utilizados en [Inteligencia Artificial](https://iaarbook.github.io/inteligencia-artificial/) y la [Ciencia de Datos](https://iaarbook.github.io/datascience/); es un lenguaje de programación de alto nivel que se caracteriza por hacer hincapié en una sintaxis limpia, que favorece un código legible y fácilmente administrable.

<a name="R"></a>
### R <a name="rlang"></a>
[R](https://iaarbook.github.io/rlang/) es un lenguaje de programación interpretado diseñado específicamente para el análisis estadístico y la manipulación de datos. Junto con [Python](#Python) son los lenguajes más populares en [Ciencia de Datos](https://iaarbook.github.io/datascience/).

### Red Neuronal <a name="RedNeuronal"></a>
Las [Redes Neuronales](https://es.wikipedia.org/wiki/Red_neuronal_artificial) son un modelo computacional basado en un gran conjunto de unidades neuronales simples ([neuronas artificiales](https://es.wikipedia.org/wiki/Neurona_de_McCulloch-Pitts)), de forma aproximadamente análoga al comportamiento observado en los axones de las neuronas en los cerebros biológicos. Son la unidad de trabajo fundamental del [Deep Learning](https://iaarbook.github.io/deeplearning/). 

### Regresión <a name="Regresion"></a>
En [Machine Learning](https://iaarbook.github.io/machine-learning/), la [Regresión](https://es.wikipedia.org/wiki/An%C3%A1lisis_de_la_regresi%C3%B3n) consiste en encontrar la mejor relación que representa al [conjuntos de datos](#ConjDatos). Es una caso típico del [Aprendizaje supervisado](#AprendSupervisado).

<a name="S"></a>
### Sobreajuste <a name="Sobreajuste"></a>
En [Machine Learning](https://iaarbook.github.io/machine-learning/) un [modelo](#Modelo) va a estar [sobreajustado](http://relopezbriega.github.io/blog/2016/05/29/machine-learning-con-python-sobreajuste/) cuando vemos que se desempeña bien con los datos de entrenamiento, pero su precisión es notablemente más baja con los datos de evaluación; esto se debe a que el modelo ha memorizado los datos que ha visto y no pudo *generalizar* las reglas para predecir los datos que no ha visto.

### SVM <a name="SVM"></a>
Las máquinas de vectores de soporte o [SVM](https://es.wikipedia.org/wiki/M%C3%A1quinas_de_vectores_de_soporte) es un [algoritmo](#Algoritmo) de [Machine Learning](https://iaarbook.github.io/machine-learning/) cuya idea central consiste en encontrar un plano que separe los grupos dentro de los datos de la mejor forma posible. Aquí, la separación significa que la elección del plano maximiza el margen entre los puntos más cercanos en el plano; éstos puntos se denominan vectores de soporte.

<a name="T"></a>
### Tensor <a name="Tensor"></a>
Un [Tensor](https://es.wikipedia.org/wiki/C%C3%A1lculo_tensorial) un un arreglo de números que generaliza los conceptos de <a href="https://es.wikipedia.org/wiki/Escalar_(matem%C3%A1tica)">escalares</a>, [vectores](#Vector), y [matrices](#Matriz) a un grado mayor de dimensiones. Es la estructura de datos fundamental que utilizan los principales frameworks de [Deep Learning](https://iaarbook.github.io/deeplearning/).

### TensorFlow <a name="Tensor"></a>
[TensorFlow](https://www.tensorflow.org/) es un frameworks desarrollado por Google para [Deep Learning](https://iaarbook.github.io/deeplearning/). Es una librería de código libre para computación numérica usando grafos de flujo de datos. Actualmente es la librería más popular para el armado de modelos de [Deep Learning](https://iaarbook.github.io/deeplearning/).

<a name="V"></a>
### Vector <a name="Vector"></a>
Un [vector](http://es.wikipedia.org/wiki/Vector) es una serie de números. Los números tienen una orden preestablecido, y podemos identificar cada número individual por su índice en ese orden. Podemos pensar en los vectores como la identificación de puntos en el espacio, con cada elemento que da la coordenada a lo largo de un eje diferente.

### Visión por computadora <a name="Vision"></a>
La [Visión por computadora](https://iaarbook.github.io/vision-por-computadora/) es una disciplina científica que incluye métodos para adquirir, procesar, analizar y comprender las imágenes del mundo real con el fin de producir información numérica o simbólica para que puedan ser tratados por una computadora. Es una de las ramas de la [Inteligencia Artificial](https://iaarbook.github.io/inteligencia-artificial/).


